{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to test combinations of monitors. Testing aborted due to the performance of DE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load ThirdEye and SelfOracle best configuations\n",
    "icse= pd.read_csv('results\\old\\smoothgrad-icse20_t95.csv')\n",
    "ood= pd.read_csv('results\\old\\smoothgrad-ood_t95.csv')\n",
    "mutants= pd.read_csv('results\\old\\smoothgrad-mutants_t95.csv')\n",
    "\n",
    "group1_df = pd.concat([icse, ood], ignore_index=True)\n",
    "ty_95 = pd.concat([group1_df, mutants], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load ThirdEye and SelfOracle best configuations\n",
    "icse= pd.read_csv('results\\old\\smoothgrad-icse20_t99.csv')\n",
    "ood= pd.read_csv('results\\old\\smoothgrad-ood_t99.csv')\n",
    "mutants= pd.read_csv('results\\old\\smoothgrad-mutants_t99.csv')\n",
    "\n",
    "group1_df = pd.concat([icse, ood], ignore_index=True)\n",
    "ty_99 = pd.concat([group1_df, mutants], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load ThirdEye and SelfOracle best configuations\n",
    "icse= pd.read_csv(r'results\\old\\track1-MSE-latent2-selforacle-icse20-t95.csv')\n",
    "ood= pd.read_csv(r'results\\old\\track1-MSE-latent2-selforacle-ood-t95.csv')\n",
    "mutants= pd.read_csv(r'results\\old\\track1-MSE-latent2-selforacle-mutants-t95.csv')\n",
    "\n",
    "group1_df = pd.concat([icse, ood], ignore_index=True)\n",
    "df = pd.concat([group1_df, mutants], ignore_index=True)\n",
    "df = df[df['aggregation_type']=='max']\n",
    "so_95 = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load ThirdEye and SelfOracle best configuations\n",
    "icse= pd.read_csv(r'results\\old\\track1-MSE-latent2-selforacle-icse20-t999.csv')\n",
    "ood= pd.read_csv(r'results\\old\\track1-MSE-latent2-selforacle-ood-t999.csv')\n",
    "mutants= pd.read_csv(r'results\\old\\track1-MSE-latent2-selforacle-mutants-t999.csv')\n",
    "\n",
    "group1_df = pd.concat([icse, ood], ignore_index=True)\n",
    "df = pd.concat([group1_df, mutants], ignore_index=True)\n",
    "df = df[df['aggregation_type']=='max']\n",
    "so_999 = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "de3_999 = pd.read_csv(r'results\\final_999\\dave2-track1-DE_3.csv')\n",
    "de5_9999 = pd.read_csv(r'results\\final_9999\\dave2-track1-DE_5.csv')\n",
    "mcd5_S64_999 = pd.read_csv(r'results\\final_999\\dave2-p10-track1-mcd_5_S64.csv')\n",
    "mcd5_S123_99999 = pd.read_csv(r'results\\final_99999\\dave2-p10-track1-mcd_5_S128.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of strings to replace\n",
    "# Strings to replace\n",
    "strings_to_replace = ['icse20\\\\', 'ood\\\\', 'mutants\\\\']\n",
    "\n",
    "# Escape the backslash (\\) in the strings for regex\n",
    "strings_to_replace = [s.replace('\\\\', '\\\\\\\\') for s in strings_to_replace]\n",
    "\n",
    "# Replace the strings with an empty string\n",
    "ty_95['simulation_name'] = ty_95['simulation_name'].replace(strings_to_replace, '', regex=True)\n",
    "ty_99['simulation_name'] = ty_99['simulation_name'].replace(strings_to_replace, '', regex=True)\n",
    "so_95['simulation_name'] = so_95['simulation_name'].replace(strings_to_replace, '', regex=True)\n",
    "so_999['simulation_name'] = so_999['simulation_name'].replace(strings_to_replace, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1_dfs = [so_95, so_999]\n",
    "group2_dfs = [mcd5_S64_999, mcd5_S123_99999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_95.name = 'so_95'\n",
    "so_999.name = 'so_999'\n",
    "mcd5_S64_999.name = 'mcd5_S64_999'\n",
    "mcd5_S123_99999.name = 'mcd5_S123_99999'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the merged DataFrames\n",
    "merged_dfs = []\n",
    "\n",
    "# Iterate through the combinations of DataFrames\n",
    "for i, df1 in enumerate(group1_dfs):\n",
    "    for j, df2 in enumerate(group2_dfs):\n",
    "        # Merge DataFrames based on 'simulation_name' and 'ttm'\n",
    "        merged_df = df1.merge(df2, on=['simulation_name', 'ttm'], suffixes=('_model1', '_model2'))\n",
    "        \n",
    "        # Convert the columns to sets of integers\n",
    "        merged_df['detected_failure_ids_model1'] = merged_df['detected_failure_ids_model1'].apply(lambda x: set(map(int, ast.literal_eval(x))))\n",
    "        merged_df['detected_failure_ids_model2'] = merged_df['detected_failure_ids_model2'].apply(lambda x: set(map(int, ast.literal_eval(x))))\n",
    "        merged_df['undetected_failure_ids_model1'] = merged_df['undetected_failure_ids_model1'].apply(lambda x: set(map(int, ast.literal_eval(x))))\n",
    "        merged_df['undetected_failure_ids_model2'] = merged_df['undetected_failure_ids_model2'].apply(lambda x: set(map(int, ast.literal_eval(x))))\n",
    "\n",
    "        # Create the 'undetected_failure_ids' column\n",
    "        def remove_detected_undetected(row):\n",
    "            # Get unique values in 'FailureIDs_model1'\n",
    "            failure_ids_model1 = set(row['FailureIDs_model1'])\n",
    "            \n",
    "            # Remove detected and undetectable failures from 'FailureIDs_model1'\n",
    "            for col_suffix in ['model1', 'model2']:\n",
    "                detected_col = f'detected_failure_ids_{col_suffix}'\n",
    "                undetectable_col = f'undetectable_failure_ids_{col_suffix}'\n",
    "                # Remove duplicates while removing detected and undetectable failures\n",
    "                failure_ids_model1 = list(set(failure_ids_model1) - set(row[detected_col]) - set(row[undetectable_col]))\n",
    "            \n",
    "            # Filter out non-integer values from the 'undetected_failure_ids' column\n",
    "            undetected_failure_ids = [value for value in failure_ids_model1 if str(value).isdigit()]\n",
    "            \n",
    "            return undetected_failure_ids\n",
    "\n",
    "        # Apply the function to create the 'undetected_failure_ids' column\n",
    "        merged_df['undetected_failure_ids'] = merged_df.apply(remove_detected_undetected, axis=1)\n",
    "\n",
    "        selected_columns = ['model', 'simulation_name', 'ttm', 'FailureIDs_model1','FailureIDs_model2', 'detected_failure_ids_model1', 'detected_failure_ids_model2', 'undetected_failure_ids_model1', 'undetected_failure_ids_model2']\n",
    "\n",
    "        merged_df = merged_df[selected_columns]\n",
    "\n",
    "        def common_undetected_ids(row):\n",
    "            # Find the common integers\n",
    "            common_ids = list(row['undetected_failure_ids_model1'].intersection(row['undetected_failure_ids_model2']))\n",
    "            return common_ids\n",
    "\n",
    "        merged_df['common_undetected_ids'] = merged_df.apply(common_undetected_ids, axis=1)\n",
    "        merged_df = merged_df[merged_df['ttm'] == 3]\n",
    "\n",
    "        # Append the merged DataFrame to the list\n",
    "        merged_dfs.append(merged_df)\n",
    "\n",
    "        # Save the merged DataFrame to a CSV file\n",
    "        file_name = f\"hybrid/{df1.name}_{df2.name}_merged.csv\"\n",
    "        merged_df.to_csv(file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Model1  Model2\n",
      "Undetected     190      31\n",
      "Detected        75     261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ruben\\anaconda3\\envs\\udacity-self-driving-car\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\udacity-self-driving-car\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\udacity-self-driving-car\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\udacity-self-driving-car\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ... (your previous code to merge DataFrames)\n",
    "\n",
    "# Create a new DataFrame with the relevant columns\n",
    "contingency_df = merged_df[['undetected_failure_ids_model1', 'undetected_failure_ids_model2', 'detected_failure_ids_model1', 'detected_failure_ids_model2']]\n",
    "\n",
    "# Convert frame lists to the count of frames\n",
    "contingency_df['undetected_failure_ids_model1'] = contingency_df['undetected_failure_ids_model1'].apply(len)\n",
    "contingency_df['undetected_failure_ids_model2'] = contingency_df['undetected_failure_ids_model2'].apply(len)\n",
    "contingency_df['detected_failure_ids_model1'] = contingency_df['detected_failure_ids_model1'].apply(len)\n",
    "contingency_df['detected_failure_ids_model2'] = contingency_df['detected_failure_ids_model2'].apply(len)\n",
    "\n",
    "# Calculate the total sums of frame counts\n",
    "undetected_model1_sum = contingency_df['undetected_failure_ids_model1'].sum()\n",
    "undetected_model2_sum = contingency_df['undetected_failure_ids_model2'].sum()\n",
    "detected_model1_sum = contingency_df['detected_failure_ids_model1'].sum()\n",
    "detected_model2_sum = contingency_df['detected_failure_ids_model2'].sum()\n",
    "\n",
    "# Create a single contingency matrix\n",
    "contingency_matrix = pd.DataFrame([[undetected_model1_sum, undetected_model2_sum], [detected_model1_sum, detected_model2_sum]],\n",
    "                                  columns=['Model1', 'Model2'],\n",
    "                                  index=['Undetected', 'Detected'])\n",
    "\n",
    "# The contingency_matrix variable now contains the single contingency matrix\n",
    "print(contingency_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "8cbfa8fa34e24f4fdf067491ee244ebd8a1ea29952b5904d83551ee7802c6909"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
